{
    "experiment": "baseline_0ex0fcv_1745664019",
    "model": "llama-3.3-70b-instruct",
    "valid_turtle_all": 0.5714,
    "valid_shacl_all": 0.1429,
    "graph_edit_distance_all": 0.7759,
    "ged_timeout_all": 1.0,
    "gbert_precision_all": 0.5116,
    "gbert_recall_all": 0.3446,
    "gbert_f1_all": 0.3726,
    "triple_accuracy_all": 0.1925,
    "triple_precision_all": 0.1553,
    "triple_recall_all": 0.0862,
    "triple_f1_all": 0.1046,
    "validation_accuracy_all": 0.0021,
    "validation_precision_all": 0.0021,
    "validation_recall_all": 0.0952,
    "validation_f1_all": 0.0041,
    "graph_edit_distance_valid_only": 0.6304,
    "ged_timeout_valid_only": 1.0,
    "gbert_precision_valid_only": 0.932,
    "gbert_recall_valid_only": 0.5321,
    "gbert_f1_valid_only": 0.6075,
    "triple_accuracy_valid_only": 0.4353,
    "triple_precision_valid_only": 0.3718,
    "triple_recall_valid_only": 0.1942,
    "triple_f1_valid_only": 0.2386,
    "validation_accuracy_valid_only": 0.0148,
    "validation_precision_valid_only": 0.0148,
    "validation_recall_valid_only": 0.6667,
    "validation_f1_valid_only": 0.0288,
    "runtime (sec)": 30.1387,
    "completion_tokens": 365.3333,
    "prompt_tokens": 8097.2857,
    "total_tokens": 8462.619
}