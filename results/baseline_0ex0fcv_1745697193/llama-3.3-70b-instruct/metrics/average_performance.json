{
    "experiment": "baseline_0ex0fcv_1745697193",
    "model": "llama-3.3-70b-instruct",
    "valid_turtle_all": 0.4762,
    "valid_shacl_all": 0.381,
    "graph_edit_distance_all": 0.8168,
    "ged_timeout_all": 1.0,
    "gbert_precision_all": 0.465,
    "gbert_recall_all": 0.2537,
    "gbert_f1_all": 0.3145,
    "triple_accuracy_all": 0.17,
    "triple_precision_all": 0.1701,
    "triple_recall_all": 0.0849,
    "triple_f1_all": 0.1121,
    "validation_precision_all": 0.006,
    "validation_recall_all": 0.3333,
    "validation_accuracy_all": 0.006,
    "validation_f1_all": 0.0118,
    "graph_edit_distance_valid_only": 0.6309,
    "ged_timeout_valid_only": 1.0,
    "gbert_precision_valid_only": 0.9783,
    "gbert_recall_valid_only": 0.4985,
    "gbert_f1_valid_only": 0.6344,
    "triple_accuracy_valid_only": 0.3804,
    "triple_precision_valid_only": 0.4017,
    "triple_recall_valid_only": 0.1942,
    "triple_f1_valid_only": 0.2595,
    "validation_precision_valid_only": 0.0159,
    "validation_recall_valid_only": 0.875,
    "validation_accuracy_valid_only": 0.0159,
    "validation_f1_valid_only": 0.0311,
    "runtime (sec)": 28.8906,
    "completion_tokens": 348.619,
    "prompt_tokens": 8109.2857,
    "total_tokens": 8457.9048
}